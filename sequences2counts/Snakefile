
__author__ = "Eilon Sharon"
__copyright__ = "Copyright 2018, Eilon Sharon, Fraser lab"
__email__ = "eilon.s@gmail.com"
__license__ = "MIT"

##########################################################################################
# input parameters (in config file)
##########################################################################################

READS = ["1","2"]
TRIM_STATE = ["raw"]

STAR_MISMATCH = ["0", "10"]
MAPPERS = ["starExact" + mismatch for mismatch in STAR_MISMATCH]
MAIN_MAPPER = "starExact0_raw"
VCF_MAPPER = "starExact10_raw"

ALL_POOLS = config['__default__']['ALL_POOLS']
EXP_POOLS = config['__default__']['EXP_POOLS']


EXPERIMENT_NAME = config['__default__']['EXPERIMENT_NAME']
INPUT_PLASMID_FILE = config['__default__']['INPUT_PLASMID_FILE']
PLASMID_SEQ_NAME = config['__default__']['PLASMID_SEQ_NAME']
POSSIBLE_CONTAMINATION_OLIGO_NAME = config['__default__']['POSSIBLE_CONTAMINATION_OLIGO_NAME']
SCRIPTS_PATH = config['__default__']['SCRIPTS_PATH']
LIB_DESIGN_NAME = config['__default__']['LIB_DESIGN_NAME']


INPUT_SAMPLES_FILE  = config['__default__']['DATA_DIR'] + "/samples_" + EXPERIMENT_NAME + ".txt"
OUTPUT_SAMPLES_FILE = "Output/" + EXPERIMENT_NAME + "/samples.txt"

print("Scripts path: " + SCRIPTS_PATH)


##########################################################################################
# printing run info
##########################################################################################

print("Running experiment: " + EXPERIMENT_NAME)
print("=" * 80)
print("Using %s as the main mapping algorithm (used for counts)" % (MAIN_MAPPER))
print("=" * 80)

##########################################################################################
# parsing samples table
##########################################################################################

import os
import pandas as pd
import numpy as np

def parse_samples_table(input_samples_table_filename, output_samples_table_filename):
	print('reading samples file: %s' % (input_samples_table_filename))
	samples_df = pd.read_table(input_samples_table_filename, sep='\t', na_values = "")

	#samples_df.induction_time_index = samples_df.induction_time_index.astype(int)
	#samples_df.competition_time_index = samples_df.competition_time_index.astype(int)


	samples_df.loc[(samples_df.competition_time == 0),'sample_ID'] = \
                           'It' + samples_df.induction_time_index[samples_df.competition_time == 0].astype(str) + \
                     '_' + 'Ir' + samples_df.induction_replicate[samples_df.competition_time  == 0].astype(str) + \
                     '_' + 'Sl' + samples_df.sequencing_lane[samples_df.competition_time  == 0].astype(str)


	samples_df.loc[(samples_df.competition_time>0),'sample_ID'] = \
                           'It' + samples_df.induction_time_index[samples_df.competition_time>0].astype(str) + \
                     '_' + 'Ir' + samples_df.induction_replicate[samples_df.competition_time>0].astype(str) + \
                     '_' + 'Ct' + samples_df.competition_time_index[samples_df.competition_time>0].astype(str) + \
                     '_' + 'Cr' + samples_df.competition_replicate[samples_df.competition_time>0].astype(str) + \
                     '_' + 'Cm' + samples_df.competition_medium[samples_df.competition_time>0].astype(str) + \
                     '_' + 'Sl' + samples_df.sequencing_lane[samples_df.competition_time > 0].astype(str)

	dict_sample_2_R1 = {}
	dict_sample_2_R2 = {}
	for sample,file_r1,file_r2 in zip(samples_df['sample_ID'].tolist(), samples_df['Sequencing_reads_R1'].tolist(), samples_df['Sequencing_reads_R2'].tolist()):
		dict_sample_2_R1[sample] = file_r1
		dict_sample_2_R2[sample] = file_r2


	# saving parsed table name
	if output_samples_table_filename:
		out_dir = os.path.dirname(output_samples_table_filename)
		if not os.path.exists(out_dir):
			os.makedirs(out_dir)
		samples_df.to_csv(output_samples_table_filename, sep='\t', index = False)

	return( (samples_df['sample_ID'].tolist(), dict_sample_2_R1, dict_sample_2_R2)     )


SAMPLES, SAMPLE_2_R1_DICT, SAMPLE_2_R2_DICT = parse_samples_table(INPUT_SAMPLES_FILE, OUTPUT_SAMPLES_FILE)

print('Samples: %s' % (str(SAMPLES)))


##########################################################################################
# create jobs directory
##########################################################################################

JOBS_DIR = "Output/" + EXPERIMENT_NAME + "/jobs_files"

if not os.path.exists(JOBS_DIR):
    os.makedirs(JOBS_DIR)


##########################################################################################
# all
##########################################################################################


rule all:
	input:
		merged_count_table = "Output/" + EXPERIMENT_NAME + "/counts/counts.tsv",
		multiqc_out="Output/" + EXPERIMENT_NAME + "/multi_reports/multiqc_report.html",
		pool_with_counts="Output/" + EXPERIMENT_NAME + "/Figures/pool_with_counts.tsv",

##########################################################################################
# copying sequencing files
##########################################################################################

rule cp_sequencing_files:
	input:
		r1 = lambda wildcards: SAMPLE_2_R1_DICT[wildcards.sample],
		r2 = lambda wildcards: SAMPLE_2_R2_DICT[wildcards.sample],
	output: 
		r1 = "Output/" + EXPERIMENT_NAME + "/sequencing/raw/{sample,[^\/]+}.raw.R1.fastq.gz",
		r2 = "Output/" + EXPERIMENT_NAME + "/sequencing/raw/{sample,[^\/]+}.raw.R2.fastq.gz"
	params:
		job_out_dir="Output/" + EXPERIMENT_NAME + "/jobs_files",
		job_out_file="cp_reads_{sample}",
		job_name="cp_reads_{sample}",
		run_time="04:00:00",
		cores="1",
		memory="4"
	shell:
		"cp {input.r1} {output.r1}; "
		"cp {input.r2} {output.r2}; "
		"touch {output.r1}; "
		"touch {output.r2}; "



##########################################################################################
# preparing the library reference for mapping
##########################################################################################

# joining pool files into one fasta file
rule pools2fa:
	input:
		pools=expand("../lib_design/Output/pools/{pool}.txt", pool=ALL_POOLS),
		plasmid = INPUT_PLASMID_FILE
	output:
		fa    = "Output/" + EXPERIMENT_NAME + "/lib_reference/lib_pools.fa",
		table = "Output/" + EXPERIMENT_NAME + "/lib_reference/lib_pools.tab"
	params:
		job_out_dir="Output/" + EXPERIMENT_NAME + "/jobs_files",
		job_out_file="pools2fa",
		job_name="pools2fa",
		run_time="02:00:00",
		cores="1",
		memory="8"
	script:
		SCRIPTS_PATH + "/crispr_ana_pools2fa.py"

# params: threads=8
rule build_star_index:
	input:
		ref_fa="Output/" + EXPERIMENT_NAME + "/lib_reference/lib_pools.fa"
	output:
		"Output/" + EXPERIMENT_NAME + "/lib_reference/SAindex"
	params:
		job_out_dir="Output/" + EXPERIMENT_NAME + "/jobs_files",
		job_out_file="build_star_index",
		job_name="build_star_index",
		run_time="20:00:00",
		cores="2",
		memory="16"
	threads: 2
	log: 
		"Output/" + EXPERIMENT_NAME + "/logs/star/indexing.log"
	shell:
		"(STAR --runMode genomeGenerate"
		" --runThreadN {threads}"
		" --genomeDir Output/{EXPERIMENT_NAME}/lib_reference --genomeFastaFiles {input.ref_fa}"
		" --genomeSAindexNbases	11 --genomeChrBinNbits 8) 2> {log}"

##########################################################################################
# mapping reads using STAR
##########################################################################################

rule map_reads_using_STAR:
	input:
		fastq_file_r1 = "Output/" + EXPERIMENT_NAME + "/sequencing/{trimstate}/{sample}.{trimstate}.R1.fastq.gz",
		fastq_file_r2 = "Output/" + EXPERIMENT_NAME + "/sequencing/{trimstate}/{sample}.{trimstate}.R2.fastq.gz",
		lib_index     = "Output/" + EXPERIMENT_NAME + "/lib_reference/SAindex"
	output:
		"Output/" + EXPERIMENT_NAME + "/mapping/starExact{maxmismatch,\d+}_{trimstate, \D+}/{sample, [^\/]+}.Aligned.out.bam"
	params:
		lib_reference_dir = "Output/" + EXPERIMENT_NAME + "/lib_reference",
		output_prefix = "Output/" + EXPERIMENT_NAME + "/mapping/starExact{maxmismatch}_{trimstate}/{sample}.",
		job_out_dir="Output/" + EXPERIMENT_NAME + "/jobs_files",
		job_out_file="map_starExact{maxmismatch}_{trimstate}_{sample}",
		job_name="map_starExact{maxmismatch}_{trimstate}_{sample}",
		run_time="47:59:00",
		cores="4",
		memory="31"
	threads: 4
	log: 
		"Output/" + EXPERIMENT_NAME + "/logs/star/starExact{maxmismatch}_{trimstate}.mapping.{sample}.log"
	shell:
		"(STAR --runThreadN {threads} --runMode alignReads"
		" --genomeDir {params.lib_reference_dir}"
		" --readFilesIn {input.fastq_file_r1} {input.fastq_file_r2}"
		" --readFilesCommand zcat"
		" --outFileNamePrefix {params.output_prefix}"
		" --outSAMtype BAM Unsorted"
		" --outFilterMultimapNmax 1"
		" --outReadsUnmapped Fastx"
		" --outFilterMismatchNmax {wildcards.maxmismatch}"
		" ) 2> {log}"


rule count_mapped_reads_STAR:
	input:
		mapped_reads = "Output/" + EXPERIMENT_NAME + "/mapping/starExact{maxmismatch}_{trimstate}/{sample}.Aligned.out.bam",
		uniq_table   = "Output/" + EXPERIMENT_NAME + "/lib_reference/lib_pools.tab"
	output:
		count_table = "Output/" + EXPERIMENT_NAME + "/counts/starExact{maxmismatch, \d+}_{trimstate, \D+}/counts_{sample}.tsv.gz",
		plasmid_count_table = "Output/" + EXPERIMENT_NAME + "/counts/starExact{maxmismatch,\d+}_{trimstate}/plasmid_counts_{sample}.tsv.gz"
	params: 
		col_name         = "{sample}",
		plasmid_seq_name = PLASMID_SEQ_NAME,
		plasmid_contamination_oligo_name = POSSIBLE_CONTAMINATION_OLIGO_NAME,
		min_tlen = lambda wildcards: config["count_mapped_reads_STAR"][wildcards.trimstate + "_min_tlen"],
		max_tlen = lambda wildcards: config["count_mapped_reads_STAR"][wildcards.trimstate + "_max_tlen"],
		max_5prime_pos = lambda wildcards: config["count_mapped_reads_STAR"][wildcards.trimstate + "_max_5prime_pos"],
		min_mapped_read1_len = lambda wildcards: config["count_mapped_reads_STAR"][wildcards.trimstate + "_min_mapped_read1_len"],
		min_mapped_read2_len = lambda wildcards: config["count_mapped_reads_STAR"][wildcards.trimstate + "_min_mapped_read2_len"],
		job_out_dir      = "Output/" + EXPERIMENT_NAME + "/jobs_files",
		job_out_file     = "count_starExact{maxmismatch}_{trimstate}_{sample}",
		job_name         = "count_starExact{maxmismatch}_{trimstate}_{sample}",
		run_time         = "95:59:00",
		cores            = "2",
		memory           = "16"
	shell:
		"{SCRIPTS_PATH}/crispr_ana_count_mapped_reads.py"
		" {input.mapped_reads}"
		" {params.col_name}"
		" {params.plasmid_seq_name}"
		" {params.plasmid_contamination_oligo_name}"
		" {input.uniq_table}"
		" {output.count_table}"
		" {output.plasmid_count_table}"
		" -s {params.min_tlen}"
		" -l {params.max_tlen}"
		" -1 {params.min_mapped_read1_len}"
		" -2 {params.min_mapped_read2_len}"


rule merge_read_counts_STAR:
	input:
		count_tables = expand("Output/" + EXPERIMENT_NAME + "/counts/starExact{{maxmismatch}}_{{trimstate}}/counts_{sample}.tsv.gz",sample=SAMPLES)
	output:
		merged_count_table = "Output/" + EXPERIMENT_NAME + "/counts/starExact{maxmismatch,\d+}_{trimstate, \D+}/counts.tsv"
	params: 
		job_out_dir="Output/" + EXPERIMENT_NAME + "/jobs_files",
		job_out_file = "merge_counts_starExact{maxmismatch}_{trimstate}",
		job_name     = "merge_counts_starExact{maxmismatch}_{trimstate}",
		run_time     = "23:59:00",
		cores        = "1",
		memory       = "16"
	shell:
		"{SCRIPTS_PATH}/crispr_ana_merge_read_counts.py"
		" {output.merged_count_table} -t {input.count_tables}"

rule merge_read_plasmid_counts_STAR:
	input:
		count_tables = expand("Output/" + EXPERIMENT_NAME + "/counts/starExact{{maxmismatch}}_{{trimstate}}/plasmid_counts_{sample}.tsv.gz",sample=SAMPLES)
	output:
		merged_count_table = "Output/" + EXPERIMENT_NAME + "/counts/starExact{maxmismatch}_{trimstate}/plasmid_counts.tsv"
	params: 
		job_out_dir="Output/" + EXPERIMENT_NAME + "/jobs_files",
		job_out_file = "merge_plasmid_counts_starExact{maxmismatch}_{trimstate}",
		job_name     = "merge_plasmid_counts_starExact{maxmismatch}_{trimstate}",
		run_time     = "2:00:00",
		cores        = "1",
		memory       = "4"
	shell:
		"{SCRIPTS_PATH}/crispr_ana_merge_read_counts.py"
		" {output.merged_count_table} -t {input.count_tables}"

###################################
# main mapper
###################################

rule cp_main_read_counts:
	input:
		cnt = "Output/" + EXPERIMENT_NAME + "/counts/" + MAIN_MAPPER + "/counts.tsv",
		cnt_plasmid = "Output/" + EXPERIMENT_NAME + "/counts/" + MAIN_MAPPER + "/plasmid_counts.tsv"
	output:
		cnt = "Output/" + EXPERIMENT_NAME + "/counts/counts.tsv",
		cnt_plasmid = "Output/" + EXPERIMENT_NAME + "/counts/plasmid_counts.tsv"
	params: 
		job_out_dir  = "Output/" + EXPERIMENT_NAME + "/jobs_files",
		job_out_file = "cp_main_mapper_counts",
		job_name     = "cp_main_mapper_counts",
		run_time     = "23:59:00",
		cores        = "1",
		memory       = "4"
	shell:
		"cp {input.cnt} {output.cnt};"
		"cp {input.cnt_plasmid} {output.cnt_plasmid};"


##########################################################################################
# testing whether oligo sequence was as designed by variant calling (using STAR mapping)
##########################################################################################

rule run_samtools_index:
	input:
		ref_fa = "Output/" + EXPERIMENT_NAME + "/lib_reference/lib_pools.fa"
	output:
		ref_idx = "Output/" + EXPERIMENT_NAME + "/lib_reference/lib_pools.fa.fai"
	params:
		job_out_dir="Output/" + EXPERIMENT_NAME + "/jobs_files",
		job_out_file="samtools_idx",
		job_name="samtools_idx",
		run_time="23:59:00",
		cores="1",
		memory="16"
	shell:
		"samtools faidx {input.ref_fa};"

rule run_sort_bams:
	input:
		mapped_reads_bam = "Output/" + EXPERIMENT_NAME + "/mapping/" + VCF_MAPPER + "/{sample}.Aligned.out.bam"
	output:
		mapped_reads_bam_sorted = "Output/" + EXPERIMENT_NAME + "/mapping/" + VCF_MAPPER + "/{sample}.Aligned.out.sorted.bam"
	params:
		job_out_dir="Output/" + EXPERIMENT_NAME + "/jobs_files",
		job_out_file="sort_bam_{sample}",
		job_name="sort_bam_{sample}",
		run_time="47:59:00",
		cores="4",
		memory="30"
	shell:
		"samtools sort {input.mapped_reads_bam} -o {output.mapped_reads_bam_sorted};"

rule run_call_oligo_varients:
	input:
		ref_fa = "Output/" + EXPERIMENT_NAME + "/lib_reference/lib_pools.fa",
		ref_idx = "Output/" + EXPERIMENT_NAME + "/lib_reference/lib_pools.fa.fai",
		mapped_reads_sorted_bams = expand("Output/" + EXPERIMENT_NAME + "/mapping/" + VCF_MAPPER + "/{sample}.Aligned.out.sorted.bam",sample=SAMPLES)
	output:
		pool_variants_vcf = "Output/" + EXPERIMENT_NAME + "/variant/lib_pools.var.raw.vcf"
	params:
		job_out_dir="Output/" + EXPERIMENT_NAME + "/jobs_files",
		job_out_file="samtools_mpileup",
		job_name="samtools_mpileup",
		run_time="47:59:00",
		cores="4",
		memory="30"
	shell:
		"samtools mpileup -u -v -o {output.pool_variants_vcf} -f {input.ref_fa} {input.mapped_reads_sorted_bams};"


##########################################################################################
# QC
##########################################################################################

rule run_fastqc_unmapped:
	input:
		fastq_file_r1 = "Output/" + EXPERIMENT_NAME + "/sequencing/{trim_state}/{sample}.{trim_state}.R1.fastq.gz",
		fastq_file_r2 = "Output/" + EXPERIMENT_NAME + "/sequencing/{trim_state}/{sample}.{trim_state}.R2.fastq.gz"
	output:
		"Output/" + EXPERIMENT_NAME + "/fq_reports/{trim_state}/{sample}.{trim_state}.R1_fastqc.html",
		"Output/" + EXPERIMENT_NAME + "/fq_reports/{trim_state}/{sample}.{trim_state}.R2_fastqc.html",
		"Output/" + EXPERIMENT_NAME + "/fq_reports/{trim_state}/{sample}.{trim_state}.R1_fastqc.zip",
		"Output/" + EXPERIMENT_NAME + "/fq_reports/{trim_state}/{sample}.{trim_state}.R2_fastqc.zip"
	params:
		job_out_dir="Output/" + EXPERIMENT_NAME + "/jobs_files",
		job_out_file="fqQC_{sample}_{trim_state}",
		job_name="fqQC_{sample}_{trim_state}",
		run_time="23:59:00",
		cores="2",
		memory="16"
	shell:
		"fastqc {input.fastq_file_r1} {input.fastq_file_r2} --outdir=Output/{EXPERIMENT_NAME}/fq_reports/{wildcards.trim_state}/"


rule run_fastqc_mapped:
	input:
		bam = "Output/" + EXPERIMENT_NAME + "/mapping/{mapper}_{trimstate}/{sample}.Aligned.out.bam"
	output:
		"Output/" + EXPERIMENT_NAME + "/fq_reports/mapped/{mapper}_{trimstate, \D+}/{sample}.Aligned.out_fastqc.html",
		"Output/" + EXPERIMENT_NAME + "/fq_reports/mapped/{mapper}_{trimstate, \D+}/{sample}.Aligned.out_fastqc.zip"
	params:
		outdir = "Output/" + EXPERIMENT_NAME +"/fq_reports/mapped/{mapper}_{trimstate}/",
		job_out_dir="Output/" + EXPERIMENT_NAME + "/jobs_files",
		job_out_file="fqQC_{mapper}_{trimstate}_{sample}_mapped",
		job_name="fqQC_{mapper}_{trimstate}_{sample}_mapped",
		run_time="23:59:00",
		cores="2",
		memory="16"
	shell:
		"fastqc {input.bam} --outdir={params.outdir}"

rule multiqc:
	input:
		fastqc_reads=expand("Output/" + EXPERIMENT_NAME + "/fq_reports/{trim_state}/{sample}.{trim_state}.R{read}_fastqc.{suf}",read=READS, trim_state=TRIM_STATE, sample=SAMPLES,suf=['html','zip']),
		fastqc_mapped=expand("Output/" + EXPERIMENT_NAME + "/fq_reports/mapped/{mapper}_{trimstate}/{sample}.Aligned.out_fastqc.{suf}",sample=SAMPLES,suf=['html','zip'], mapper=MAPPERS, trimstate=TRIM_STATE)
	output:
		report= "Output/" + EXPERIMENT_NAME + "/multi_reports/multiqc_report.html",
	params:
		job_out_dir="Output/" + EXPERIMENT_NAME + "/jobs_files",
		job_out_file="multiQC",
		job_name="multiQC",
		run_time="47:59:00",
		cores="4",
		memory="31"
	shell:
		"multiqc Output/{EXPERIMENT_NAME} -o Output/{EXPERIMENT_NAME}/multi_reports -f"

##########################################################################################
# preparing library design data frames
##########################################################################################

rule prepare_lib_design:
	input:
		oligos_for_SNPs_in_selected_qtls_df_filename = "../lib_design/Output/lib_design/all_SNPs_in_selected_QTLs_bothPolForGeneNonForSNP_V1_GG_17bp_OLIGO.tab",
		oligos_for_SNPs_not_in_selected_qtls_df_filename = "../lib_design/Output/lib_design/all_SNPs_not_in_selected_QTLs_bothPolForGeneNonForSNP_V1_GG_17bp_OLIGO.tab",
		oligos_for_genes_in_selected_qtls_df_filename = "../lib_design/Output/lib_design/selected_QTL_genes_bothPolForGeneNonForSNP_V1_GG_17bp_OLIGO.tab",
		oligos_for_essential_genes_df_filename = "../lib_design/Output/lib_design/essential_genes_bothPolForGeneNonForSNP_V1_GG_17bp_OLIGO.tab",
		oligos_for_essential_genes_1bpMut_df_filename = "../lib_design/Output/lib_design/essential_genes_1bpMut_bothPolForGeneNonForSNP_V1_GG_17bp_OLIGO.tab",
		oligos_for_essential_genes_stop2aa_df_filename = "../lib_design/Output/lib_design/essential_genes_stop2aa_bothPolForGeneNonForSNP_V1_GG_17bp_OLIGO.tab",
		exp_pools=expand("../lib_design/Output/pools/{pool}.txt",pool=EXP_POOLS)
	output:
		exp_nonuniq_df="Output/" + EXPERIMENT_NAME + "/lib_design/exp_oligo_nonuniq.tsv",
		exp_pool_df="Output/" + EXPERIMENT_NAME + "/lib_design/exp_oligo_pool.tsv"
	params:
		job_out_dir="Output/" + EXPERIMENT_NAME + "/jobs_files",
		job_out_file="prepare_lib_design",
		job_name="prepare_lib_design",
		run_time="01:00:00",
		cores="1",
		memory="8"
	shell:
		"python {SCRIPTS_PATH}/crispr_ana_prepare_lib_design.py "
		"../  {LIB_DESIGN_NAME} {EXPERIMENT_NAME} -p {input.exp_pools};"


##########################################################################################
# drawing initial analysis figures (QC)
##########################################################################################

rule parse_counts:
	input:
		exp_nonuniq_df="Output/" + EXPERIMENT_NAME + "/lib_design/exp_oligo_nonuniq.tsv",
		exp_pool_df="Output/" + EXPERIMENT_NAME + "/lib_design/exp_oligo_pool.tsv",
		merged_count_table = "Output/" + EXPERIMENT_NAME + "/counts/counts.tsv"
	output:
		pool_with_counts="Output/" + EXPERIMENT_NAME + "/Figures/pool_with_counts.tsv"
	params:
		job_out_dir="Output/" + EXPERIMENT_NAME + "/jobs_files",
		job_out_file="parse_counts",
		job_name="parse_counts",
		run_time="01:00:00",
		cores="1",
		memory="8"
	shell:
		"python {SCRIPTS_PATH}/crispr_ana_parse_counts.py "
		"../  {LIB_DESIGN_NAME} {EXPERIMENT_NAME};"
